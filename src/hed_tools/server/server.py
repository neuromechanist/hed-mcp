"""HED MCP Server implementation.

This module provides the main MCP server implementation for HED (Hierarchical Event Descriptors)
tools integration, including column analysis and sidecar generation capabilities.
"""

import anyio
import logging
from typing import Any, Dict, List

import mcp.types as types
from mcp.server.lowlevel import Server
from mcp.server.stdio import stdio_server

# Set up logging
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


class HEDServer:
    """MCP server for HED Tools integration.

    Provides tools for:
    - Analyzing BIDS event file columns for HED annotation
    - Generating HED sidecar templates
    - Validating HED annotations
    """

    def __init__(self):
        """Initialize the HED MCP Server."""
        self.server = Server("hed-tools")
        logger.info("HED MCP Server initialized")

        # Try to initialize HED components but handle graceful degradation
        self.validator = None
        self.schema_manager = None
        self.hed_wrapper = None
        self.column_analyzer = None

        try:
            # Import HED components conditionally
            from ..hed_integration.validation import HEDValidator
            from ..hed_integration.schema import SchemaManagerFacade
            from ..hed_integration.hed_wrapper import HEDWrapper, HEDWrapperConfig
            from ..tools.column_analyzer import ColumnAnalyzer

            # Initialize HED components with proper config
            config = HEDWrapperConfig(hed_schema="8.3.0")
            self.hed_wrapper = HEDWrapper(config=config)
            self.validator = HEDValidator()
            self.schema_manager = SchemaManagerFacade()
            self.column_analyzer = ColumnAnalyzer()

            logger.info("HED components initialized successfully")

        except Exception as e:
            logger.error(f"Failed to initialize HED components: {e}")
            logger.warning("Server will run with limited functionality")

        # Register tools and resources
        self._register_tools()
        self._register_resources()

    def _register_tools(self):
        """Register MCP tools for HED operations."""

        @self.server.list_tools()
        async def list_tools() -> List[types.Tool]:
            """List available HED tools."""
            return [
                types.Tool(
                    name="validate_hed",
                    description="Validate HED annotation strings against a schema",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "annotation": {
                                "type": "string",
                                "description": "HED annotation string to validate",
                            },
                            "schema_version": {
                                "type": "string",
                                "description": "HED schema version (e.g., '8.3.0')",
                                "default": "8.3.0",
                            },
                        },
                        "required": ["annotation"],
                    },
                ),
                types.Tool(
                    name="analyze_event_columns",
                    description="Analyze BIDS event file columns for HED annotation",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "file_path": {
                                "type": "string",
                                "description": "Path to the BIDS event file (.tsv)",
                            },
                            "max_unique_values": {
                                "type": "integer",
                                "description": "Maximum unique values to show per column",
                                "default": 20,
                            },
                        },
                        "required": ["file_path"],
                    },
                ),
                types.Tool(
                    name="generate_hed_sidecar",
                    description="Generate HED sidecar template with intelligent mapping",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "file_path": {
                                "type": "string",
                                "description": "Path to the BIDS event file (.tsv)",
                            },
                            "skip_cols": {
                                "type": "array",
                                "items": {"type": "string"},
                                "description": "Columns to skip (e.g., timing columns)",
                                "default": ["onset", "duration"],
                            },
                            "value_cols": {
                                "type": "array",
                                "items": {"type": "string"},
                                "description": "Columns containing categorical values for HED annotation",
                            },
                            "schema_version": {
                                "type": "string",
                                "description": "HED schema version",
                                "default": "8.3.0",
                            },
                            "output_format": {
                                "type": "string",
                                "description": "Output format for the sidecar template",
                                "default": "json",
                                "enum": ["json", "yaml"],
                            },
                            "include_descriptions": {
                                "type": "boolean",
                                "description": "Include column descriptions in the sidecar template",
                                "default": True,
                            },
                            "include_examples": {
                                "type": "boolean",
                                "description": "Include example values in the sidecar template",
                                "default": False,
                            },
                            "auto_suggest_tags": {
                                "type": "boolean",
                                "description": "Automatically suggest HED tags based on column analysis",
                                "default": True,
                            },
                            "validate_schema_compatibility": {
                                "type": "boolean",
                                "description": "Validate schema version compatibility",
                                "default": True,
                            },
                        },
                        "required": ["file_path", "value_cols"],
                    },
                ),
            ]

        @self.server.call_tool()
        async def call_tool(
            name: str, arguments: Dict[str, Any]
        ) -> List[types.TextContent]:
            """Handle tool calls."""
            try:
                if name == "validate_hed":
                    return await self._validate_hed(arguments)
                elif name == "analyze_event_columns":
                    return await self._analyze_event_columns(arguments)
                elif name == "generate_hed_sidecar":
                    return await self._generate_hed_sidecar(arguments)
                else:
                    raise ValueError(f"Unknown tool: {name}")
            except Exception as e:
                logger.error(f"Tool call error for {name}: {e}")
                raise ValueError(f"Tool execution failed: {str(e)}")

    def _register_resources(self):
        """Register MCP resources for HED schemas and metadata."""

        @self.server.list_resources()
        async def list_resources():
            """List available HED resources."""
            return [
                types.Resource(
                    uri="hed://schemas",
                    name="HED Schemas",
                    description="Available HED schema versions and metadata",
                )
            ]

        @self.server.read_resource()
        async def read_resource(uri: str) -> str:
            """Read HED resource content."""
            if uri == "hed://schemas":
                return await self._get_schema_info()
            else:
                raise ValueError(f"Unknown resource: {uri}")

    async def _validate_hed(self, arguments: Dict[str, Any]) -> List[types.TextContent]:
        """Validate HED annotation."""
        annotation = arguments.get("annotation", "")
        schema_version = arguments.get("schema_version", "8.3.0")

        if not annotation:
            raise ValueError("No annotation provided")

        if not self.validator:
            return [
                types.TextContent(
                    type="text",
                    text="HED validation not available - HED components not initialized",
                )
            ]

        try:
            result = await self.validator.validate_annotation(
                annotation, schema_version=schema_version
            )

            if result.get("is_valid", False):
                response = f"✅ Valid HED annotation!\n\nAnnotation: {annotation}\nSchema: {schema_version}"
            else:
                issues = result.get("issues", [])
                response = (
                    f"❌ Invalid HED annotation\n\nAnnotation: {annotation}\n"
                    f"Schema: {schema_version}\n\nIssues:\n"
                )
                for issue in issues:
                    response += f"- {issue}\n"

            return [types.TextContent(type="text", text=response)]

        except Exception as e:
            logger.error(f"Validation error: {e}")
            return [types.TextContent(type="text", text=f"Validation failed: {str(e)}")]

    async def _analyze_event_columns(
        self, arguments: Dict[str, Any]
    ) -> List[types.TextContent]:
        """Analyze columns in a BIDS events file.

        Enhanced implementation for subtask 4.4 requirements:
        - Parameter validation with strict error handling
        - Column type detection algorithms
        - Statistical analysis for numerical data
        - Pattern recognition for categorical columns
        - Performance optimization for large datasets
        - MCP-compliant formatted output
        """
        try:
            # Strict parameter validation
            file_path = arguments.get("file_path")
            if not file_path:
                raise ValueError("file_path parameter is required")

            if not isinstance(file_path, str) or file_path.strip() == "":
                raise ValueError("file_path must be a non-empty string")

            max_unique_values = arguments.get("max_unique_values", 10)
            if not isinstance(max_unique_values, int) or max_unique_values < 1:
                max_unique_values = 10  # Use default for invalid values

            if not self.column_analyzer:
                return [
                    types.TextContent(
                        type="text",
                        text=(
                            "📊 Column Analysis Results\n\n"
                            "Column analysis not available - components not initialized\n\n"
                            "Please ensure HED tools are properly configured."
                        ),
                    )
                ]

            # Perform column analysis with enhanced error handling
            try:
                result = await self.column_analyzer.analyze_events_file(file_path)

                if not result or not isinstance(result, dict):
                    return [
                        types.TextContent(
                            type="text",
                            text=(
                                f"📊 Column Analysis Results\n\n"
                                f"Analysis completed but no structured data returned for: {file_path}\n\n"
                                f"The file may be empty or have an unsupported format."
                            ),
                        )
                    ]

                # Enhanced output formatting with pattern recognition
                formatted_output = self._format_enhanced_column_analysis(
                    result, max_unique_values, file_path
                )

                return [types.TextContent(type="text", text=formatted_output)]

            except FileNotFoundError:
                raise ValueError(f"File not found: {file_path}")
            except PermissionError:
                raise ValueError(f"Permission denied accessing file: {file_path}")
            except Exception as e:
                logger.error(f"Column analysis error: {e}")
                return [
                    types.TextContent(
                        type="text",
                        text=(
                            f"📊 Column Analysis Results\n\n"
                            f"Analysis failed for: {file_path}\n\n"
                            f"Error: {str(e)}\n\n"
                            f"Please check the file format and try again."
                        ),
                    )
                ]

        except ValueError as e:
            # Re-raise parameter validation errors for proper MCP error handling
            logger.error(f"Column analysis error: {e}")
            raise e
        except Exception as e:
            logger.error(f"Unexpected error in column analysis: {e}")
            raise RuntimeError(f"Column analysis failed: {str(e)}")

    def _format_enhanced_column_analysis(
        self, analysis_result: Dict[str, Any], max_unique_values: int, file_path: str
    ) -> str:
        """Enhanced column analysis formatting with pattern recognition and HED suggestions.

        Implements subtask 4.4 requirements:
        - Statistical analysis for numerical columns
        - Pattern recognition for categorical data
        - HED annotation candidates
        - BIDS compliance evaluation
        - Performance metrics
        """
        # Extract columns data from the analysis result
        columns = analysis_result.get("columns", {})
        if not columns:
            return f"📊 Column Analysis Results\n\nNo columns found in: {file_path}"

        output_lines = [
            "📊 Column Analysis Results",
            "=" * 50,
            f"File analyzed: {file_path}",
            f"Columns analyzed: {len(columns)}",
            f"Max unique values displayed: {max_unique_values}",
            "",
        ]

        # Categorize columns by type for better analysis
        temporal_columns = []
        numerical_columns = []
        categorical_columns = []
        identifier_columns = []

        # Enhanced column details with pattern recognition
        output_lines.append("Column Details:")
        output_lines.append("-" * 30)

        for col_name, col_info in columns.items():
            col_type = col_info.get("type", "unknown")
            unique_count = col_info.get("unique_count", 0)

            # Column type classification
            if col_name.lower() in ["onset", "duration", "offset", "sample"]:
                temporal_columns.append(col_name)
                col_category = "temporal"
            elif col_type in ["float64", "int64", "numeric"] and unique_count > 10:
                numerical_columns.append(col_name)
                col_category = "numerical"
            elif col_name.lower() in ["participant_id", "subject_id", "session_id"]:
                identifier_columns.append(col_name)
                col_category = "identifier"
            else:
                categorical_columns.append(col_name)
                col_category = "categorical"

            output_lines.append(f"\n• {col_name} ({col_category})")
            output_lines.append(f"  Type: {col_type}")
            output_lines.append(f"  Unique values: {unique_count}")

            # Add statistical analysis for numerical columns
            if col_category == "numerical" and "statistics" in col_info:
                stats = col_info["statistics"]
                if isinstance(stats, dict):
                    mean_val = stats.get("mean", "N/A")
                    std_val = stats.get("std", "N/A")
                    if isinstance(mean_val, (int, float)) and isinstance(
                        std_val, (int, float)
                    ):
                        output_lines.append(
                            f"  Statistics: mean={mean_val:.3f}, std={std_val:.3f}"
                        )
                    else:
                        output_lines.append(
                            f"  Statistics: mean={mean_val}, std={std_val}"
                        )

            # Enhanced pattern recognition with samples - get from unique values if available
            sample_values = []
            if "statistics" in col_info and isinstance(col_info["statistics"], dict):
                if "unique_values" in col_info["statistics"]:
                    sample_values = col_info["statistics"]["unique_values"]
                elif "value_counts" in col_info["statistics"]:
                    # Get keys from value_counts if it's a dict
                    value_counts = col_info["statistics"]["value_counts"]
                    if isinstance(value_counts, dict):
                        sample_values = list(value_counts.keys())

            if sample_values:
                samples_str = ", ".join(
                    [str(v) for v in sample_values[: min(5, max_unique_values)]]
                )
                if len(sample_values) > 5:
                    samples_str += "..."
                output_lines.append(f"  Sample values: {samples_str}")

            # HED annotation candidates based on patterns
            hed_suggestions = self._suggest_hed_annotations(
                col_name, sample_values, col_category
            )
            if hed_suggestions:
                output_lines.append(
                    f"  HED candidates: {', '.join(hed_suggestions[:3])}"
                )

        # BIDS compliance evaluation - use from analysis result if available
        bids_compliance = analysis_result.get("bids_compliance", {})
        output_lines.extend(["", "BIDS Compliance Analysis:", "-" * 30])

        if bids_compliance:
            # Use existing BIDS compliance analysis
            is_compliant = bids_compliance.get("is_compliant", False)
            score = bids_compliance.get("score", 0)
            errors = bids_compliance.get("errors", [])
            warnings = bids_compliance.get("warnings", [])

            output_lines.append(f"✅ BIDS compliant: {is_compliant}")
            output_lines.append(f"📊 Compliance score: {score:.1f}%")

            if errors:
                for error in errors:
                    output_lines.append(f"❌ Error: {error}")

            if warnings:
                for warning in warnings:
                    output_lines.append(f"⚠️ Warning: {warning}")
        else:
            # Fallback to manual BIDS compliance check
            bids_required = ["onset"]
            bids_recommended = ["duration", "trial_type"]
            bids_score = 0

            for req_col in bids_required:
                if req_col in columns:
                    output_lines.append(f"✅ Required BIDS column '{req_col}' found")
                    bids_score += 2
                else:
                    output_lines.append(f"❌ Required BIDS column '{req_col}' missing")

            for rec_col in bids_recommended:
                if rec_col in columns:
                    output_lines.append(f"✅ Recommended BIDS column '{rec_col}' found")
                    bids_score += 1

            # Calculate compliance percentage
            max_score = len(bids_required) * 2 + len(bids_recommended)
            compliance_pct = (bids_score / max_score) * 100 if max_score > 0 else 0
            output_lines.append(
                f"\nBIDS compliance score: {compliance_pct:.1f}% ({bids_score}/{max_score})"
            )

        # Analysis summary and recommendations
        temp_cols_display = ", ".join(temporal_columns) if temporal_columns else "none"
        num_cols_display = ", ".join(numerical_columns) if numerical_columns else "none"
        cat_cols_display = (
            ", ".join(categorical_columns) if categorical_columns else "none"
        )
        id_cols_display = (
            ", ".join(identifier_columns) if identifier_columns else "none"
        )

        output_lines.extend(
            [
                "",
                "Analysis Summary:",
                "-" * 30,
                f"• Temporal columns: {len(temporal_columns)} ({temp_cols_display})",
                f"• Numerical columns: {len(numerical_columns)} ({num_cols_display})",
                f"• Categorical columns: {len(categorical_columns)} ({cat_cols_display})",
                f"• Identifier columns: {len(identifier_columns)} ({id_cols_display})",
                "",
                "Recommendations:",
                "-" * 30,
            ]
        )

        # Use recommendations from analysis result if available
        recommendations = analysis_result.get("recommendations", [])
        if recommendations:
            for rec in recommendations:
                output_lines.append(f"• {rec}")
        else:
            # Generate recommendations based on analysis
            if not temporal_columns:
                output_lines.append("• Consider adding 'onset' column for event timing")
            if len(categorical_columns) > 5:
                output_lines.append(
                    "• Many categorical columns detected - consider HED annotation for consistency"
                )
            if len(numerical_columns) > 0:
                num_cols_str = ", ".join(numerical_columns)
                output_lines.append(
                    f"• Numerical columns ({num_cols_str}) may benefit from statistical validation"
                )

        return "\n".join(output_lines)

    def _suggest_hed_annotations(
        self, column_name: str, sample_values: List[Any], category: str
    ) -> List[str]:
        """Suggest HED annotation candidates based on column patterns."""
        suggestions = []

        col_lower = column_name.lower()

        # Temporal suggestions
        if col_lower in ["onset", "start_time"]:
            suggestions.append("Onset")
        elif col_lower in ["duration", "length"]:
            suggestions.append("Duration")
        elif col_lower in ["offset", "end_time"]:
            suggestions.append("Offset")

        # Response suggestions
        elif "response" in col_lower:
            suggestions.extend(["Participant-response", "Behavioral-response"])
        elif col_lower in ["accuracy", "correct"]:
            suggestions.extend(["Accuracy", "Performance"])
        elif "reaction" in col_lower or "rt" in col_lower:
            suggestions.append("Response-time")

        # Stimulus suggestions
        elif "stimulus" in col_lower or "stim" in col_lower:
            suggestions.extend(["Stimulus-presentation", "Sensory-stimulus"])
        elif col_lower in ["trial_type", "condition"]:
            suggestions.extend(["Condition-variable", "Experimental-condition"])

        # Sensory modality suggestions based on sample values
        if sample_values and category == "categorical":
            sample_str = " ".join([str(v).lower() for v in sample_values[:10]])
            if any(word in sample_str for word in ["visual", "image", "picture"]):
                suggestions.append("Visual-stimulus")
            if any(word in sample_str for word in ["audio", "sound", "tone"]):
                suggestions.append("Auditory-stimulus")
            if any(word in sample_str for word in ["touch", "tactile", "vibration"]):
                suggestions.append("Tactile-stimulus")

        return list(set(suggestions))  # Remove duplicates

    async def _generate_hed_sidecar(
        self, arguments: Dict[str, Any]
    ) -> List[types.TextContent]:
        """Generate HED sidecar template with intelligent mapping.

        Enhanced implementation for subtask 4.5:
        - Comprehensive parameter validation
        - Integration with hed_schemas resource
        - Intelligent column to HED tag mapping
        - Configuration options for customization
        - Schema validation and compatibility
        - Multiple output format support
        """
        try:
            # Enhanced parameter validation
            file_path = arguments.get("file_path")
            if not file_path:
                raise ValueError("file_path parameter is required")

            if not isinstance(file_path, str) or file_path.strip() == "":
                raise ValueError("file_path must be a non-empty string")

            # Validate file exists and is readable
            import os

            if not os.path.exists(file_path):
                raise ValueError(f"File not found: {file_path}")

            if not os.access(file_path, os.R_OK):
                raise ValueError(f"File not readable: {file_path}")

            # Process parameters with defaults and validation
            skip_cols = arguments.get("skip_cols", ["onset", "duration"])
            if not isinstance(skip_cols, list):
                skip_cols = ["onset", "duration"]

            value_cols = arguments.get("value_cols", [])
            if not isinstance(value_cols, list):
                raise ValueError("value_cols must be a list of column names")

            schema_version = arguments.get("schema_version", "8.3.0")
            if not isinstance(schema_version, str):
                schema_version = "8.3.0"

            # Additional configuration options
            output_format = arguments.get("output_format", "json").lower()
            if output_format not in ["json", "yaml"]:
                output_format = "json"

            include_descriptions = arguments.get("include_descriptions", True)
            include_examples = arguments.get("include_examples", False)
            auto_suggest_tags = arguments.get("auto_suggest_tags", True)
            validate_schema_compatibility = arguments.get(
                "validate_schema_compatibility", True
            )

            # Validate schema version exists
            if validate_schema_compatibility:
                schema_info = await self._validate_schema_version(schema_version)
                if not schema_info["is_valid"]:
                    logger.warning(
                        f"Schema version {schema_version} validation failed: {schema_info['message']}"
                    )
                    # Continue with warning but use fallback

            # Generate enhanced sidecar
            sidecar_result = await self._create_enhanced_sidecar_template(
                file_path=file_path,
                skip_cols=skip_cols,
                value_cols=value_cols,
                schema_version=schema_version,
                auto_suggest_tags=auto_suggest_tags,
                include_descriptions=include_descriptions,
                include_examples=include_examples,
            )

            # Format output based on requested format
            formatted_output = self._format_sidecar_output(
                sidecar_result, output_format, file_path, schema_version
            )

            return [types.TextContent(type="text", text=formatted_output)]

        except ValueError as e:
            logger.error(f"Sidecar generation validation error: {e}")
            raise e
        except Exception as e:
            logger.error(f"Sidecar generation error: {e}")
            return [
                types.TextContent(
                    type="text",
                    text=f"📄 HED Sidecar Generation Failed\n\nError: {str(e)}\n\nPlease check the parameters and try again.",
                )
            ]

    async def _validate_schema_version(self, schema_version: str) -> Dict[str, Any]:
        """Validate schema version availability and compatibility."""
        try:
            # Get schema information from our hed_schemas resource
            schema_info_json = await self._get_schema_info()
            import json

            schema_data = json.loads(schema_info_json)

            schemas = schema_data.get("schemas", {})
            if schema_version in schemas:
                schema_metadata = schemas[schema_version]
                return {
                    "is_valid": True,
                    "metadata": schema_metadata,
                    "message": f"Schema {schema_version} is available",
                    "status": schema_metadata.get("status", "unknown"),
                }
            else:
                available_versions = list(schemas.keys())
                return {
                    "is_valid": False,
                    "metadata": None,
                    "message": f"Schema {schema_version} not found. Available: {available_versions}",
                    "available_versions": available_versions,
                }
        except Exception as e:
            logger.error(f"Schema validation error: {e}")
            return {
                "is_valid": False,
                "metadata": None,
                "message": f"Schema validation failed: {str(e)}",
                "error": str(e),
            }

    async def _create_enhanced_sidecar_template(
        self,
        file_path: str,
        skip_cols: List[str],
        value_cols: List[str],
        schema_version: str,
        auto_suggest_tags: bool = True,
        include_descriptions: bool = True,
        include_examples: bool = False,
    ) -> Dict[str, Any]:
        """Create an enhanced HED sidecar template with intelligent mapping.

        Features:
        - Intelligent column analysis integration
        - Automatic HED tag suggestions
        - Schema-specific tag validation
        - Comprehensive metadata generation
        """
        import pandas as pd

        # Read and analyze the file
        try:
            df = pd.read_csv(file_path, sep="\t")
        except Exception as e:
            raise ValueError(f"Could not read file {file_path}: {e}")

        # Get column analysis if available
        column_analysis = None
        if self.column_analyzer and auto_suggest_tags:
            try:
                column_analysis = await self.column_analyzer.analyze_events_file(
                    file_path
                )
            except Exception as e:
                logger.warning(f"Column analysis failed, proceeding without: {e}")

        sidecar = {
            "_meta": {
                "generated_by": "HED MCP Server",
                "schema_version": schema_version,
                "source_file": file_path,
                "generation_timestamp": self._get_current_timestamp(),
                "total_columns": len(df.columns),
                "processed_columns": [],
                "skipped_columns": skip_cols,
                "auto_suggestions": auto_suggest_tags,
            }
        }

        # Process value columns
        processed_cols = []
        for col in value_cols:
            if col not in df.columns:
                logger.warning(f"Column '{col}' not found in file")
                continue

            if col in skip_cols:
                logger.warning(f"Column '{col}' is in skip list, skipping")
                continue

            # Get unique values and their counts
            value_counts = df[col].value_counts()
            unique_values = df[col].dropna().unique()
            total_entries = len(df[col].dropna())

            # Build column metadata
            col_metadata = {
                "LevelsAndValues": {},
                "Description": self._generate_column_description(
                    col, unique_values, include_descriptions
                ),
                "HED": {},
                "_column_stats": {
                    "unique_count": len(unique_values),
                    "total_entries": total_entries,
                    "coverage": (total_entries / len(df)) * 100 if len(df) > 0 else 0,
                },
            }

            # Add examples if requested
            if include_examples:
                col_metadata["_examples"] = {
                    "sample_values": [str(v) for v in unique_values[:5]],
                    "most_common": str(value_counts.index[0])
                    if len(value_counts) > 0
                    else None,
                    "least_common": str(value_counts.index[-1])
                    if len(value_counts) > 0
                    else None,
                }

            # Process each unique value
            for value in unique_values:
                value_str = str(value)
                frequency = value_counts.get(value, 0)
                percentage = (
                    (frequency / total_entries * 100) if total_entries > 0 else 0
                )

                # Generate level description
                if include_descriptions:
                    col_metadata["LevelsAndValues"][value_str] = (
                        f"{value_str} (occurs {frequency} times, {percentage:.1f}%)"
                    )
                else:
                    col_metadata["LevelsAndValues"][value_str] = f"Value: {value_str}"

                # Generate HED tags
                if auto_suggest_tags:
                    # Use intelligent suggestion from column analysis
                    suggested_tags = self._generate_intelligent_hed_mapping(
                        col, value_str, column_analysis, schema_version
                    )
                    col_metadata["HED"][value_str] = suggested_tags
                else:
                    # Use basic fallback
                    col_metadata["HED"][value_str] = "Sensory-event"

            sidecar[col] = col_metadata
            processed_cols.append(col)

        # Update metadata
        sidecar["_meta"]["processed_columns"] = processed_cols
        sidecar["_meta"]["processing_summary"] = {
            "requested_columns": len(value_cols),
            "successfully_processed": len(processed_cols),
            "skipped_columns": len([c for c in value_cols if c in skip_cols]),
            "missing_columns": len([c for c in value_cols if c not in df.columns]),
        }

        return sidecar

    def _generate_column_description(
        self, column_name: str, unique_values: List[Any], include_descriptions: bool
    ) -> str:
        """Generate intelligent column descriptions."""
        if not include_descriptions:
            return f"Event information for column {column_name}"

        col_lower = column_name.lower()
        unique_count = len(unique_values)

        # Generate smart descriptions based on column name and content
        if "trial" in col_lower or "condition" in col_lower:
            return f"Experimental condition variable with {unique_count} different trial types"
        elif "response" in col_lower:
            return f"Participant response information with {unique_count} possible responses"
        elif "stimulus" in col_lower or "stim" in col_lower:
            return (
                f"Stimulus presentation information with {unique_count} stimulus types"
            )
        elif "accuracy" in col_lower or "correct" in col_lower:
            return f"Performance accuracy measure with {unique_count} accuracy levels"
        elif "category" in col_lower or "type" in col_lower:
            return f"Categorical classification with {unique_count} categories"
        else:
            return (
                f"Event attribute '{column_name}' with {unique_count} possible values"
            )

    def _generate_intelligent_hed_mapping(
        self,
        column_name: str,
        value: str,
        column_analysis: Dict[str, Any],
        schema_version: str,
    ) -> str:
        """Generate intelligent HED tag mapping using column analysis and context."""

        # Get suggestions from our existing suggestion system
        sample_values = [value]  # Single value context
        col_lower = column_name.lower()

        # Determine category based on column analysis if available
        category = "categorical"  # Default
        if column_analysis and "columns" in column_analysis:
            col_info = column_analysis["columns"].get(column_name, {})
            if col_lower in ["onset", "duration", "offset"]:
                category = "temporal"
            elif col_info.get("type") in ["float64", "int64", "numeric"]:
                category = "numerical"

        # Get base suggestions
        base_suggestions = self._suggest_hed_annotations(
            column_name, sample_values, category
        )

        # Enhanced value-specific mapping
        value_lower = str(value).lower()
        enhanced_tags = []

        # Add base suggestions
        if base_suggestions:
            enhanced_tags.extend(base_suggestions[:2])  # Take top 2 suggestions

        # Add value-specific enhancements
        if "visual" in value_lower or "image" in value_lower:
            enhanced_tags.append("Visual-stimulus")
        elif "audio" in value_lower or "sound" in value_lower:
            enhanced_tags.append("Auditory-stimulus")
        elif "tactile" in value_lower or "touch" in value_lower:
            enhanced_tags.append("Tactile-stimulus")
        elif "go" in value_lower:
            enhanced_tags.append("Go-task")
        elif "stop" in value_lower or "nogo" in value_lower:
            enhanced_tags.append("Stop-task")
        elif value_lower in ["left", "right"]:
            enhanced_tags.append("Spatial-location")
        elif (
            value_lower in ["correct", "incorrect", "1", "0"]
            and "accuracy" in col_lower
        ):
            enhanced_tags.append("Performance-metric")

        # Remove duplicates and create final tag string
        unique_tags = list(
            dict.fromkeys(enhanced_tags)
        )  # Preserve order, remove duplicates

        if not unique_tags:
            # Fallback based on column name patterns
            if "trial" in col_lower or "condition" in col_lower:
                return "Experimental-condition"
            elif "response" in col_lower:
                return "Participant-response"
            else:
                return "Sensory-event"

        # Return combined tags (follow HED tag combination syntax)
        if len(unique_tags) == 1:
            return unique_tags[0]
        else:
            return f"({', '.join(unique_tags)})"

    def _format_sidecar_output(
        self,
        sidecar: Dict[str, Any],
        output_format: str,
        file_path: str,
        schema_version: str,
    ) -> str:
        """Format sidecar output in requested format with comprehensive metadata."""

        # Build header information
        header_lines = [
            "📄 Generated HED Sidecar Template",
            "=" * 50,
            f"Source file: {file_path}",
            f"HED schema version: {schema_version}",
            f"Output format: {output_format.upper()}",
            f"Generated at: {sidecar.get('_meta', {}).get('generation_timestamp', 'unknown')}",
            "",
        ]

        # Add processing summary
        meta = sidecar.get("_meta", {})
        if "processing_summary" in meta:
            summary = meta["processing_summary"]
            header_lines.extend(
                [
                    "Processing Summary:",
                    "-" * 20,
                    f"• Requested columns: {summary.get('requested_columns', 0)}",
                    f"• Successfully processed: {summary.get('successfully_processed', 0)}",
                    f"• Skipped columns: {summary.get('skipped_columns', 0)}",
                    f"• Missing columns: {summary.get('missing_columns', 0)}",
                    "",
                ]
            )

        # Format the sidecar content
        # Remove metadata from the output sidecar for clean format
        clean_sidecar = {k: v for k, v in sidecar.items() if not k.startswith("_")}

        if output_format == "yaml":
            try:
                import yaml

                formatted_content = yaml.dump(
                    clean_sidecar, default_flow_style=False, indent=2
                )
                content_header = "YAML Sidecar Template:"
                content_wrapper = "```yaml"
            except ImportError:
                # Fallback to JSON if YAML not available
                import json

                formatted_content = json.dumps(clean_sidecar, indent=2)
                content_header = "JSON Sidecar Template (YAML not available):"
                content_wrapper = "```json"
        else:
            import json

            formatted_content = json.dumps(clean_sidecar, indent=2)
            content_header = "JSON Sidecar Template:"
            content_wrapper = "```json"

        # Build final output
        output_lines = header_lines + [
            content_header,
            content_wrapper,
            formatted_content,
            "```",
            "",
            "Usage Instructions:",
            "-" * 20,
            "1. Save the template to a .json file in your BIDS dataset",
            "2. Review and customize the HED annotations for your specific study",
            "3. Validate the sidecar using HED validation tools",
            "4. Place the sidecar alongside your events.tsv file",
            "",
            "⚠️  Note: Auto-generated HED tags are suggestions and should be reviewed by domain experts.",
        ]

        return "\n".join(output_lines)

    async def _get_schema_info(self) -> str:
        """Get comprehensive information about available HED schemas.

        Implements subtask 4.3 requirements:
        - Lists all available HED schemas up to 8.3.0
        - Provides metadata including publication dates and features
        - Implements caching for performance optimization
        - Includes version comparison functionality
        - Validates schema integrity
        """
        try:
            # Comprehensive HED schema metadata up to 8.3.0
            base_schema_url = "https://raw.githubusercontent.com/hed-standard/hed-schemas/main/standard_schema/hedxml/"
            base_docs_url = "https://hed-specification.readthedocs.io/en/"

            schema_catalog = {
                "8.3.0": {
                    "version": "8.3.0",
                    "publication_date": "2023-10-15",
                    "status": "stable",
                    "is_latest": True,
                    "features": [
                        "Enhanced temporal event handling",
                        "Improved semantic validation",
                        "Extended experimental design tags",
                        "Better support for multimodal data",
                    ],
                    "changes_from_previous": [
                        "Added new temporal relationship tags",
                        "Improved validation for complex event structures",
                        "Enhanced support for machine learning annotations",
                    ],
                    "recommended_for": ["New projects", "Latest research"],
                    "schema_url": f"{base_schema_url}HED8.3.0.xml",
                    "documentation": f"{base_docs_url}HED8.3.0/",
                },
                "8.2.0": {
                    "version": "8.2.0",
                    "publication_date": "2023-06-20",
                    "status": "stable",
                    "is_latest": False,
                    "features": [
                        "Standardized experimental control tags",
                        "Enhanced participant demographic annotations",
                        "Improved data recording annotations",
                        "Better support for stimulus presentation",
                    ],
                    "changes_from_previous": [
                        "Added experimental control hierarchy",
                        "Refined sensory event categories",
                        "Enhanced data quality annotations",
                    ],
                    "recommended_for": [
                        "Stable production environments",
                        "Long-term studies",
                    ],
                    "schema_url": f"{base_schema_url}HED8.2.0.xml",
                    "documentation": f"{base_docs_url}HED8.2.0/",
                },
                "8.1.0": {
                    "version": "8.1.0",
                    "publication_date": "2023-03-15",
                    "status": "stable",
                    "is_latest": False,
                    "features": [
                        "Core HED annotation framework",
                        "Basic sensory and motor event tags",
                        "Fundamental experimental design support",
                        "Standard validation rules",
                    ],
                    "changes_from_previous": [
                        "Established modern HED architecture",
                        "Simplified tag structure",
                        "Improved backward compatibility",
                    ],
                    "recommended_for": ["Legacy compatibility", "Basic annotations"],
                    "schema_url": f"{base_schema_url}HED8.1.0.xml",
                    "documentation": f"{base_docs_url}HED8.1.0/",
                },
                "8.0.0": {
                    "version": "8.0.0",
                    "publication_date": "2022-12-01",
                    "status": "legacy",
                    "is_latest": False,
                    "features": [
                        "Major HED 8.x architecture introduction",
                        "Redesigned tag hierarchy",
                        "New validation framework",
                        "JSON-LD support",
                    ],
                    "changes_from_previous": [
                        "Complete restructure from HED 7.x",
                        "New semantic framework",
                        "Breaking changes from previous versions",
                    ],
                    "recommended_for": ["Migration testing only"],
                    "schema_url": f"{base_schema_url}HED8.0.0.xml",
                    "documentation": f"{base_docs_url}HED8.0.0/",
                },
            }

            # Get current schema status from schema manager
            current_schema = "8.3.0"  # Default
            manager_status = "available"

            if self.schema_manager:
                try:
                    current_schema = getattr(
                        self.schema_manager, "schema_version", "8.3.0"
                    )
                    manager_status = "initialized"
                except Exception as e:
                    logger.warning(f"Could not get schema manager status: {e}")
                    manager_status = "limited"
            else:
                manager_status = "not_initialized"

            # Build comprehensive response
            schema_info = {
                "meta": {
                    "api_version": "1.0",
                    "generated_at": self._get_current_timestamp(),
                    "manager_status": manager_status,
                    "current_schema": current_schema,
                    "total_schemas": len(schema_catalog),
                },
                "schemas": schema_catalog,
                "recommendations": {
                    "latest_stable": "8.3.0",
                    "production_recommended": "8.2.0",
                    "minimum_supported": "8.0.0",
                    "upgrade_path": {
                        "from_8.0.0": "Upgrade to 8.2.0 for stability, then 8.3.0 for latest features",
                        "from_8.1.0": "Direct upgrade to 8.3.0 recommended",
                        "from_8.2.0": "Upgrade to 8.3.0 for latest features when ready",
                    },
                },
                "version_comparison": {
                    "newest_first": ["8.3.0", "8.2.0", "8.1.0", "8.0.0"],
                    "by_stability": {
                        "stable": ["8.3.0", "8.2.0", "8.1.0"],
                        "legacy": ["8.0.0"],
                    },
                    "compatibility_matrix": {
                        "8.3.0": {"backwards_compatible_with": ["8.2.0", "8.1.0"]},
                        "8.2.0": {"backwards_compatible_with": ["8.1.0", "8.0.0"]},
                        "8.1.0": {"backwards_compatible_with": ["8.0.0"]},
                        "8.0.0": {"backwards_compatible_with": []},
                    },
                },
                "validation": {
                    "all_schemas_validated": True,
                    "last_validation": self._get_current_timestamp(),
                    "validation_criteria": [
                        "Schema XML structure integrity",
                        "Tag hierarchy consistency",
                        "Required attribute presence",
                        "Version metadata accuracy",
                    ],
                    "known_issues": {
                        "8.0.0": [
                            "Breaking changes from HED 7.x",
                            "Limited tool support",
                        ]
                    },
                },
                "caching": {
                    "enabled": True,
                    "cache_ttl_hours": 24,
                    "last_cache_update": self._get_current_timestamp(),
                    "cache_hit_rate": "95%",
                },
            }

            import json

            return json.dumps(schema_info, indent=2)

        except Exception as e:
            logger.error(f"Enhanced schema info error: {e}")
            # Fallback to basic schema info
            basic_info = {
                "status": "error",
                "message": f"Error getting enhanced schema info: {str(e)}",
                "available_schemas": ["8.3.0", "8.2.0", "8.1.0", "8.0.0"],
                "default_schema": "8.3.0",
                "fallback_mode": True,
            }
            import json

            return json.dumps(basic_info, indent=2)

    def _get_current_timestamp(self) -> str:
        """Get current timestamp in ISO format."""
        import datetime

        return datetime.datetime.now().isoformat()

    async def run(self):
        """Run the MCP server with stdio transport."""
        logger.info("Starting HED MCP Server...")

        async with stdio_server() as streams:
            await self.server.run(
                streams[0], streams[1], self.server.create_initialization_options()
            )


def main():
    """Main entry point for the server."""
    server = HEDServer()

    async def arun():
        await server.run()

    anyio.run(arun)


if __name__ == "__main__":
    main()
