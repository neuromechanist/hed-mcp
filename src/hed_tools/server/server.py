"""HED MCP Server implementation.

This module provides the main MCP server implementation for HED (Hierarchical Event Descriptors)
tools integration, including column analysis and sidecar generation capabilities.
"""

import asyncio
import logging
import warnings
from datetime import datetime
from typing import Any, Dict, List
import time
import hashlib
import secrets
from functools import wraps

import mcp.types as types
from mcp.server.lowlevel import Server
from mcp.server.stdio import stdio_server

# Import components with graceful degradation
try:
    from hed_tools.hed_integration.hed_wrapper import HEDWrapper
    from hed_tools.tools.column_analyzer import ColumnAnalyzer
    from hed_tools.tools.hed_validator import HEDValidator
    from hed_tools.tools.performance_optimizer import PerformanceOptimizer
    from hed_tools.utils.error_handler import ErrorHandler
    from hed_tools.utils.logger import setup_logger
except ImportError as e:
    warnings.warn(f"Could not import HED components: {e}")
    HEDWrapper = None
    ColumnAnalyzer = None
    HEDValidator = None
    PerformanceOptimizer = None
    ErrorHandler = None
    setup_logger = None

# Set up logging
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = setup_logger(__name__) if setup_logger else logging.getLogger(__name__)


# Security configuration
class SecurityConfig:
    """Security configuration for production deployment."""

    def __init__(self):
        self.api_key_header = "X-API-Key"
        self.max_request_size = 10 * 1024 * 1024  # 10MB
        self.rate_limit_window = 60  # seconds
        self.rate_limit_requests = 100  # per window
        self.session_timeout = 3600  # 1 hour
        self.allowed_file_types = [".tsv", ".csv", ".txt"]
        self.max_file_size = 50 * 1024 * 1024  # 50MB

    def generate_session_token(self) -> str:
        """Generate a secure session token."""
        return secrets.token_urlsafe(32)

    def hash_api_key(self, api_key: str) -> str:
        """Hash API key for secure storage."""
        return hashlib.sha256(api_key.encode()).hexdigest()


# Rate limiting decorator
def rate_limit(max_requests: int = 100, window_seconds: int = 60):
    """Rate limiting decorator for tool methods."""
    request_history = {}

    def decorator(func):
        @wraps(func)
        async def wrapper(self, *args, **kwargs):
            client_id = getattr(self, "_client_id", "default")
            current_time = time.time()

            # Clean old entries
            if client_id in request_history:
                request_history[client_id] = [
                    req_time
                    for req_time in request_history[client_id]
                    if current_time - req_time < window_seconds
                ]
            else:
                request_history[client_id] = []

            # Check rate limit
            if len(request_history[client_id]) >= max_requests:
                error_msg = f"Rate limit exceeded: {max_requests} requests per {window_seconds} seconds"
                logger.warning(f"Rate limit exceeded for client {client_id}")
                raise ValueError(error_msg)

            # Add current request
            request_history[client_id].append(current_time)

            return await func(self, *args, **kwargs)

        return wrapper

    return decorator


# Error handling decorators and utilities
class MCPErrorHandler:
    """Centralized error handling for MCP protocol compliance."""

    @staticmethod
    def handle_tool_error(tool_name: str):
        """Decorator for standardized tool error handling."""

        def decorator(func):
            @wraps(func)
            async def wrapper(*args, **kwargs):
                try:
                    return await func(*args, **kwargs)
                except ValueError as e:
                    logger.error(f"Validation error in {tool_name}: {e}")
                    return [
                        types.TextContent(
                            type="text",
                            text=(
                                f"âŒ {tool_name} Error\n\n"
                                f"Validation failed: {str(e)}\n\n"
                                f"Please check your parameters and try again."
                            ),
                        )
                    ]
                except FileNotFoundError as e:
                    logger.error(f"File not found in {tool_name}: {e}")
                    return [
                        types.TextContent(
                            type="text",
                            text=(
                                f"âŒ {tool_name} Error\n\n"
                                f"File not found: {str(e)}\n\n"
                                f"Please verify the file path exists and is accessible."
                            ),
                        )
                    ]
                except PermissionError as e:
                    logger.error(f"Permission error in {tool_name}: {e}")
                    return [
                        types.TextContent(
                            type="text",
                            text=(
                                f"âŒ {tool_name} Error\n\n"
                                f"Permission denied: {str(e)}\n\n"
                                f"Please check file permissions and access rights."
                            ),
                        )
                    ]
                except asyncio.TimeoutError as e:
                    logger.error(f"Timeout in {tool_name}: {e}")
                    return [
                        types.TextContent(
                            type="text",
                            text=(
                                f"âŒ {tool_name} Error\n\n"
                                f"Operation timed out: {str(e)}\n\n"
                                f"The operation took too long to complete. "
                                f"Please try again or reduce the data size."
                            ),
                        )
                    ]
                except Exception as e:
                    logger.error(f"Unexpected error in {tool_name}: {e}", exc_info=True)
                    return [
                        types.TextContent(
                            type="text",
                            text=(
                                f"âŒ {tool_name} Error\n\n"
                                f"Unexpected error occurred: {str(e)}\n\n"
                                f"This has been logged for investigation. "
                                f"Please try again or contact support."
                            ),
                        )
                    ]

            return wrapper

        return decorator

    @staticmethod
    def log_request_context(tool_name: str, arguments: Dict[str, Any]):
        """Log request context for debugging and auditing."""
        sanitized_args = MCPErrorHandler._sanitize_arguments(arguments)
        logger.info(
            f"Tool request: {tool_name}",
            extra={
                "tool": tool_name,
                "arguments": sanitized_args,
                "timestamp": datetime.utcnow().isoformat(),
                "request_id": secrets.token_hex(8),
            },
        )

    @staticmethod
    def _sanitize_arguments(arguments: Dict[str, Any]) -> Dict[str, Any]:
        """Remove sensitive information from arguments for logging."""
        sensitive_keys = ["api_key", "token", "password", "secret"]
        sanitized = {}

        for key, value in arguments.items():
            if any(sensitive in key.lower() for sensitive in sensitive_keys):
                sanitized[key] = "[REDACTED]"
            elif isinstance(value, str) and len(value) > 200:
                sanitized[key] = f"{value[:200]}... [TRUNCATED]"
            else:
                sanitized[key] = value

        return sanitized


# Input validation and sanitization
class InputValidator:
    """Comprehensive input validation and sanitization."""

    @staticmethod
    def validate_file_path(file_path: str, security_config: SecurityConfig) -> str:
        """Validate and sanitize file path."""
        if not file_path or not isinstance(file_path, str):
            raise ValueError("File path must be a non-empty string")

        # Remove null bytes and normalize path
        file_path = file_path.replace("\0", "").strip()

        # Check for directory traversal attempts
        if ".." in file_path or file_path.startswith("/"):
            raise ValueError("Invalid file path: directory traversal not allowed")

        # Check file extension
        import os

        _, ext = os.path.splitext(file_path.lower())
        if ext not in security_config.allowed_file_types:
            raise ValueError(
                f"File type {ext} not allowed. Allowed types: {security_config.allowed_file_types}"
            )

        return file_path

    @staticmethod
    def validate_column_list(columns: List[str]) -> List[str]:
        """Validate and sanitize column list."""
        if not isinstance(columns, list):
            raise ValueError("Columns must be provided as a list")

        sanitized = []
        for col in columns:
            if not isinstance(col, str):
                raise ValueError("Column names must be strings")

            # Remove dangerous characters
            sanitized_col = col.replace("\0", "").strip()
            if not sanitized_col:
                continue

            sanitized.append(sanitized_col)

        return sanitized

    @staticmethod
    def validate_schema_version(version: str) -> str:
        """Validate HED schema version."""
        if not isinstance(version, str):
            raise ValueError("Schema version must be a string")

        # Basic format validation (major.minor.patch)
        import re

        if not re.match(r"^\d+\.\d+\.\d+$", version):
            raise ValueError(
                "Schema version must be in format 'major.minor.patch' (e.g., '8.3.0')"
            )

        return version.strip()


# Performance monitoring
class PerformanceMonitor:
    """Monitor and log performance metrics."""

    def __init__(self):
        self.request_times = {}
        self.request_counts = {}

    def start_timer(self, operation: str) -> str:
        """Start timing an operation."""
        operation_id = f"{operation}_{secrets.token_hex(4)}"
        self.request_times[operation_id] = time.time()
        return operation_id

    def end_timer(self, operation_id: str, operation: str):
        """End timing and log performance."""
        if operation_id in self.request_times:
            duration = time.time() - self.request_times[operation_id]
            del self.request_times[operation_id]

            # Update counters
            if operation not in self.request_counts:
                self.request_counts[operation] = {"count": 0, "total_time": 0}

            self.request_counts[operation]["count"] += 1
            self.request_counts[operation]["total_time"] += duration

            # Log performance
            avg_time = (
                self.request_counts[operation]["total_time"]
                / self.request_counts[operation]["count"]
            )

            logger.info(
                f"Performance: {operation}",
                extra={
                    "operation": operation,
                    "duration": duration,
                    "average_duration": avg_time,
                    "total_requests": self.request_counts[operation]["count"],
                },
            )

            # Warning for slow operations
            if duration > 10.0:  # 10 seconds
                logger.warning(
                    f"Slow operation detected: {operation} took {duration:.2f}s"
                )

    def get_stats(self) -> Dict[str, Any]:
        """Get performance statistics."""
        stats = {}
        for operation, data in self.request_counts.items():
            stats[operation] = {
                "total_requests": data["count"],
                "total_time": data["total_time"],
                "average_time": data["total_time"] / data["count"]
                if data["count"] > 0
                else 0,
            }
        return stats


class HEDServer:
    """Production-ready MCP server for HED Tools integration.

    Provides tools for:
    - Analyzing BIDS event file columns for HED annotation
    - Generating HED sidecar templates
    - Validating HED annotations

    Production features (Subtask 4.6):
    - Comprehensive error handling and MCP protocol compliance
    - Security middleware with input validation and rate limiting
    - Performance monitoring and async optimization
    - Request logging and audit trails
    - Timeout handling for long-running operations
    """

    def __init__(self):
        """Initialize the production-ready HED MCP Server."""
        self.server = Server("hed-tools")
        logger.info("HED MCP Server initialized")

        # Initialize production components
        self.security_config = SecurityConfig()
        self.performance_monitor = PerformanceMonitor()
        self._client_id = "default"  # Can be set from connection context

        # Connection pool and async optimization settings
        self.max_concurrent_requests = 10
        self.request_timeout = 30.0  # seconds
        self.semaphore = asyncio.Semaphore(self.max_concurrent_requests)

        # Try to initialize HED components but handle graceful degradation
        self.validator = None
        self.schema_manager = None
        self.hed_wrapper = None
        self.column_analyzer = None

        try:
            # Import HED components conditionally
            from ..hed_integration.validation import HEDValidator
            from ..hed_integration.schema import SchemaManagerFacade
            from ..hed_integration.hed_wrapper import HEDWrapper, HEDWrapperConfig
            from ..tools.column_analyzer import ColumnAnalyzer

            # Initialize HED components with proper config
            config = HEDWrapperConfig(hed_schema="8.3.0")
            self.hed_wrapper = HEDWrapper(config=config)
            self.validator = HEDValidator()
            self.schema_manager = SchemaManagerFacade()
            self.column_analyzer = ColumnAnalyzer()

            logger.info("HED components initialized successfully")

        except Exception as e:
            logger.error(f"Failed to initialize HED components: {e}")
            logger.warning("Server will run with limited functionality")

        # Register tools and resources
        self._register_tools()
        self._register_resources()

    def _register_tools(self):
        """Register MCP tools for HED operations."""

        @self.server.list_tools()
        async def list_tools() -> List[types.Tool]:
            """List available HED tools."""
            return [
                types.Tool(
                    name="validate_hed",
                    description="Validate HED annotation strings against a schema",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "annotation": {
                                "type": "string",
                                "description": "HED annotation string to validate",
                            },
                            "schema_version": {
                                "type": "string",
                                "description": "HED schema version (e.g., '8.3.0')",
                                "default": "8.3.0",
                            },
                        },
                        "required": ["annotation"],
                    },
                ),
                types.Tool(
                    name="analyze_event_columns",
                    description="Analyze BIDS event file columns for HED annotation",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "file_path": {
                                "type": "string",
                                "description": "Path to the BIDS event file (.tsv)",
                            },
                            "max_unique_values": {
                                "type": "integer",
                                "description": "Maximum unique values to show per column",
                                "default": 20,
                            },
                        },
                        "required": ["file_path"],
                    },
                ),
                types.Tool(
                    name="generate_hed_sidecar",
                    description="Generate HED sidecar template with intelligent mapping",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "file_path": {
                                "type": "string",
                                "description": "Path to the BIDS event file (.tsv)",
                            },
                            "skip_cols": {
                                "type": "array",
                                "items": {"type": "string"},
                                "description": "Columns to skip (e.g., timing columns)",
                                "default": ["onset", "duration"],
                            },
                            "value_cols": {
                                "type": "array",
                                "items": {"type": "string"},
                                "description": "Columns containing categorical values for HED annotation",
                            },
                            "schema_version": {
                                "type": "string",
                                "description": "HED schema version",
                                "default": "8.3.0",
                            },
                            "output_format": {
                                "type": "string",
                                "description": "Output format for the sidecar template",
                                "default": "json",
                                "enum": ["json", "yaml"],
                            },
                            "include_descriptions": {
                                "type": "boolean",
                                "description": "Include column descriptions in the sidecar template",
                                "default": True,
                            },
                            "include_examples": {
                                "type": "boolean",
                                "description": "Include example values in the sidecar template",
                                "default": False,
                            },
                            "auto_suggest_tags": {
                                "type": "boolean",
                                "description": "Automatically suggest HED tags based on column analysis",
                                "default": True,
                            },
                            "validate_schema_compatibility": {
                                "type": "boolean",
                                "description": "Validate schema version compatibility",
                                "default": True,
                            },
                        },
                        "required": ["file_path", "value_cols"],
                    },
                ),
            ]

        @self.server.call_tool()
        async def call_tool(
            name: str, arguments: Dict[str, Any]
        ) -> List[types.TextContent]:
            """Handle tool calls with production-ready security and monitoring."""
            try:
                # Validate and sanitize arguments for security
                sanitized_args = self._validate_and_sanitize_arguments(name, arguments)

                # Route to appropriate tool with error handling and monitoring
                if name == "validate_hed":
                    return await self._with_timeout_and_monitoring(
                        "validate_hed", self._validate_hed_with_security(sanitized_args)
                    )
                elif name == "analyze_event_columns":
                    return await self._with_timeout_and_monitoring(
                        "analyze_event_columns",
                        self._analyze_event_columns_with_security(sanitized_args),
                    )
                elif name == "generate_hed_sidecar":
                    return await self._with_timeout_and_monitoring(
                        "generate_hed_sidecar",
                        self._generate_hed_sidecar_with_security(sanitized_args),
                    )
                else:
                    logger.error(f"Unknown tool requested: {name}")
                    raise ValueError(f"Unknown tool: {name}")

            except Exception as e:
                logger.error(f"Tool call error for {name}: {e}")
                # Return standardized error response
                return [
                    types.TextContent(
                        type="text",
                        text=(
                            f"âŒ Tool Error: {name}\n\n"
                            f"Request failed: {str(e)}\n\n"
                            f"Please check your request and try again."
                        ),
                    )
                ]

    def _register_resources(self):
        """Register MCP resources for HED schemas and metadata."""

        @self.server.list_resources()
        async def list_resources():
            """List available HED resources."""
            return [
                types.Resource(
                    uri="hed://schemas",
                    name="HED Schemas",
                    description="Available HED schema versions and metadata",
                )
            ]

        @self.server.read_resource()
        async def read_resource(uri: str) -> str:
            """Read HED resource content."""
            if uri == "hed://schemas":
                return await self._get_schema_info()
            else:
                raise ValueError(f"Unknown resource: {uri}")

    @MCPErrorHandler.handle_tool_error("validate_hed")
    @rate_limit(max_requests=50, window_seconds=60)
    async def _validate_hed_with_security(
        self, arguments: Dict[str, Any]
    ) -> List[types.TextContent]:
        """Validate HED annotation with production security."""
        return await self._validate_hed(arguments)

    @MCPErrorHandler.handle_tool_error("analyze_event_columns")
    @rate_limit(max_requests=20, window_seconds=60)
    async def _analyze_event_columns_with_security(
        self, arguments: Dict[str, Any]
    ) -> List[types.TextContent]:
        """Analyze event columns with production security."""
        return await self._analyze_event_columns(arguments)

    @MCPErrorHandler.handle_tool_error("generate_hed_sidecar")
    @rate_limit(max_requests=10, window_seconds=60)
    async def _generate_hed_sidecar_with_security(
        self, arguments: Dict[str, Any]
    ) -> List[types.TextContent]:
        """Generate HED sidecar with production security."""
        return await self._generate_hed_sidecar(arguments)

    async def _validate_hed(self, arguments: Dict[str, Any]) -> List[types.TextContent]:
        """Validate HED annotation."""
        annotation = arguments.get("annotation", "")
        schema_version = arguments.get("schema_version", "8.3.0")

        if not annotation:
            raise ValueError("No annotation provided")

        if not self.validator:
            return [
                types.TextContent(
                    type="text",
                    text="HED validation not available - HED components not initialized",
                )
            ]

        try:
            result = await self.validator.validate_annotation(
                annotation, schema_version=schema_version
            )

            if result.get("is_valid", False):
                response = f"âœ… Valid HED annotation!\n\nAnnotation: {annotation}\nSchema: {schema_version}"
            else:
                issues = result.get("issues", [])
                response = (
                    f"âŒ Invalid HED annotation\n\nAnnotation: {annotation}\n"
                    f"Schema: {schema_version}\n\nIssues:\n"
                )
                for issue in issues:
                    response += f"- {issue}\n"

            return [types.TextContent(type="text", text=response)]

        except Exception as e:
            logger.error(f"Validation error: {e}")
            return [types.TextContent(type="text", text=f"Validation failed: {str(e)}")]

    async def _analyze_event_columns(
        self, arguments: Dict[str, Any]
    ) -> List[types.TextContent]:
        """Analyze columns in a BIDS events file.

        Enhanced implementation for subtask 4.4 requirements:
        - Parameter validation with strict error handling
        - Column type detection algorithms
        - Statistical analysis for numerical data
        - Pattern recognition for categorical columns
        - Performance optimization for large datasets
        - MCP-compliant formatted output
        """
        try:
            # Strict parameter validation
            file_path = arguments.get("file_path")
            if not file_path:
                raise ValueError("file_path parameter is required")

            if not isinstance(file_path, str) or file_path.strip() == "":
                raise ValueError("file_path must be a non-empty string")

            max_unique_values = arguments.get("max_unique_values", 10)
            if not isinstance(max_unique_values, int) or max_unique_values < 1:
                max_unique_values = 10  # Use default for invalid values

            if not self.column_analyzer:
                return [
                    types.TextContent(
                        type="text",
                        text=(
                            "ðŸ“Š Column Analysis Results\n\n"
                            "Column analysis not available - components not initialized\n\n"
                            "Please ensure HED tools are properly configured."
                        ),
                    )
                ]

            # Perform column analysis with enhanced error handling
            try:
                result = await self.column_analyzer.analyze_events_file(file_path)

                if not result or not isinstance(result, dict):
                    return [
                        types.TextContent(
                            type="text",
                            text=(
                                f"ðŸ“Š Column Analysis Results\n\n"
                                f"Analysis completed but no structured data returned for: {file_path}\n\n"
                                f"The file may be empty or have an unsupported format."
                            ),
                        )
                    ]

                # Enhanced output formatting with pattern recognition
                formatted_output = self._format_enhanced_column_analysis(
                    result, max_unique_values, file_path
                )

                return [types.TextContent(type="text", text=formatted_output)]

            except FileNotFoundError:
                raise ValueError(f"File not found: {file_path}")
            except PermissionError:
                raise ValueError(f"Permission denied accessing file: {file_path}")
            except Exception as e:
                logger.error(f"Column analysis error: {e}")
                return [
                    types.TextContent(
                        type="text",
                        text=(
                            f"ðŸ“Š Column Analysis Results\n\n"
                            f"Analysis failed for: {file_path}\n\n"
                            f"Error: {str(e)}\n\n"
                            f"Please check the file format and try again."
                        ),
                    )
                ]

        except ValueError as e:
            # Re-raise parameter validation errors for proper MCP error handling
            logger.error(f"Column analysis error: {e}")
            raise e
        except Exception as e:
            logger.error(f"Unexpected error in column analysis: {e}")
            raise RuntimeError(f"Column analysis failed: {str(e)}")

    def _format_enhanced_column_analysis(
        self, analysis_result: Dict[str, Any], max_unique_values: int, file_path: str
    ) -> str:
        """Enhanced column analysis formatting with pattern recognition and HED suggestions.

        Implements subtask 4.4 requirements:
        - Statistical analysis for numerical columns
        - Pattern recognition for categorical data
        - HED annotation candidates
        - BIDS compliance evaluation
        - Performance metrics
        """
        # Extract columns data from the analysis result
        columns = analysis_result.get("columns", {})
        if not columns:
            return f"ðŸ“Š Column Analysis Results\n\nNo columns found in: {file_path}"

        output_lines = [
            "ðŸ“Š Column Analysis Results",
            "=" * 50,
            f"File analyzed: {file_path}",
            f"Columns analyzed: {len(columns)}",
            f"Max unique values displayed: {max_unique_values}",
            "",
        ]

        # Categorize columns by type for better analysis
        temporal_columns = []
        numerical_columns = []
        categorical_columns = []
        identifier_columns = []

        # Enhanced column details with pattern recognition
        output_lines.append("Column Details:")
        output_lines.append("-" * 30)

        for col_name, col_info in columns.items():
            col_type = col_info.get("type", "unknown")
            unique_count = col_info.get("unique_count", 0)

            # Column type classification
            if col_name.lower() in ["onset", "duration", "offset", "sample"]:
                temporal_columns.append(col_name)
                col_category = "temporal"
            elif col_type in ["float64", "int64", "numeric"] and unique_count > 10:
                numerical_columns.append(col_name)
                col_category = "numerical"
            elif col_name.lower() in ["participant_id", "subject_id", "session_id"]:
                identifier_columns.append(col_name)
                col_category = "identifier"
            else:
                categorical_columns.append(col_name)
                col_category = "categorical"

            output_lines.append(f"\nâ€¢ {col_name} ({col_category})")
            output_lines.append(f"  Type: {col_type}")
            output_lines.append(f"  Unique values: {unique_count}")

            # Add statistical analysis for numerical columns
            if col_category == "numerical" and "statistics" in col_info:
                stats = col_info["statistics"]
                if isinstance(stats, dict):
                    mean_val = stats.get("mean", "N/A")
                    std_val = stats.get("std", "N/A")
                    if isinstance(mean_val, (int, float)) and isinstance(
                        std_val, (int, float)
                    ):
                        output_lines.append(
                            f"  Statistics: mean={mean_val:.3f}, std={std_val:.3f}"
                        )
                    else:
                        output_lines.append(
                            f"  Statistics: mean={mean_val}, std={std_val}"
                        )

            # Enhanced pattern recognition with samples - get from unique values if available
            sample_values = []
            if "statistics" in col_info and isinstance(col_info["statistics"], dict):
                if "unique_values" in col_info["statistics"]:
                    sample_values = col_info["statistics"]["unique_values"]
                elif "value_counts" in col_info["statistics"]:
                    # Get keys from value_counts if it's a dict
                    value_counts = col_info["statistics"]["value_counts"]
                    if isinstance(value_counts, dict):
                        sample_values = list(value_counts.keys())

            if sample_values:
                samples_str = ", ".join(
                    [str(v) for v in sample_values[: min(5, max_unique_values)]]
                )
                if len(sample_values) > 5:
                    samples_str += "..."
                output_lines.append(f"  Sample values: {samples_str}")

            # HED annotation candidates based on patterns
            hed_suggestions = self._suggest_hed_annotations(
                col_name, sample_values, col_category
            )
            if hed_suggestions:
                output_lines.append(
                    f"  HED candidates: {', '.join(hed_suggestions[:3])}"
                )

        # BIDS compliance evaluation - use from analysis result if available
        bids_compliance = analysis_result.get("bids_compliance", {})
        output_lines.extend(["", "BIDS Compliance Analysis:", "-" * 30])

        if bids_compliance:
            # Use existing BIDS compliance analysis
            is_compliant = bids_compliance.get("is_compliant", False)
            score = bids_compliance.get("score", 0)
            errors = bids_compliance.get("errors", [])
            warnings = bids_compliance.get("warnings", [])

            output_lines.append(f"âœ… BIDS compliant: {is_compliant}")
            output_lines.append(f"ðŸ“Š Compliance score: {score:.1f}%")

            if errors:
                for error in errors:
                    output_lines.append(f"âŒ Error: {error}")

            if warnings:
                for warning in warnings:
                    output_lines.append(f"âš ï¸ Warning: {warning}")
        else:
            # Fallback to manual BIDS compliance check
            bids_required = ["onset"]
            bids_recommended = ["duration", "trial_type"]
            bids_score = 0

            for req_col in bids_required:
                if req_col in columns:
                    output_lines.append(f"âœ… Required BIDS column '{req_col}' found")
                    bids_score += 2
                else:
                    output_lines.append(f"âŒ Required BIDS column '{req_col}' missing")

            for rec_col in bids_recommended:
                if rec_col in columns:
                    output_lines.append(f"âœ… Recommended BIDS column '{rec_col}' found")
                    bids_score += 1

            # Calculate compliance percentage
            max_score = len(bids_required) * 2 + len(bids_recommended)
            compliance_pct = (bids_score / max_score) * 100 if max_score > 0 else 0
            output_lines.append(
                f"\nBIDS compliance score: {compliance_pct:.1f}% ({bids_score}/{max_score})"
            )

        # Analysis summary and recommendations
        temp_cols_display = ", ".join(temporal_columns) if temporal_columns else "none"
        num_cols_display = ", ".join(numerical_columns) if numerical_columns else "none"
        cat_cols_display = (
            ", ".join(categorical_columns) if categorical_columns else "none"
        )
        id_cols_display = (
            ", ".join(identifier_columns) if identifier_columns else "none"
        )

        output_lines.extend(
            [
                "",
                "Analysis Summary:",
                "-" * 30,
                f"â€¢ Temporal columns: {len(temporal_columns)} ({temp_cols_display})",
                f"â€¢ Numerical columns: {len(numerical_columns)} ({num_cols_display})",
                f"â€¢ Categorical columns: {len(categorical_columns)} ({cat_cols_display})",
                f"â€¢ Identifier columns: {len(identifier_columns)} ({id_cols_display})",
                "",
                "Recommendations:",
                "-" * 30,
            ]
        )

        # Use recommendations from analysis result if available
        recommendations = analysis_result.get("recommendations", [])
        if recommendations:
            for rec in recommendations:
                output_lines.append(f"â€¢ {rec}")
        else:
            # Generate recommendations based on analysis
            if not temporal_columns:
                output_lines.append("â€¢ Consider adding 'onset' column for event timing")
            if len(categorical_columns) > 5:
                output_lines.append(
                    "â€¢ Many categorical columns detected - consider HED annotation for consistency"
                )
            if len(numerical_columns) > 0:
                num_cols_str = ", ".join(numerical_columns)
                output_lines.append(
                    f"â€¢ Numerical columns ({num_cols_str}) may benefit from statistical validation"
                )

        return "\n".join(output_lines)

    def _suggest_hed_annotations(
        self, column_name: str, sample_values: List[Any], category: str
    ) -> List[str]:
        """Suggest HED annotation candidates based on column patterns."""
        suggestions = []

        col_lower = column_name.lower()

        # Temporal suggestions
        if col_lower in ["onset", "start_time"]:
            suggestions.append("Onset")
        elif col_lower in ["duration", "length"]:
            suggestions.append("Duration")
        elif col_lower in ["offset", "end_time"]:
            suggestions.append("Offset")

        # Response suggestions
        elif "response" in col_lower:
            suggestions.extend(["Participant-response", "Behavioral-response"])
        elif col_lower in ["accuracy", "correct"]:
            suggestions.extend(["Accuracy", "Performance"])
        elif "reaction" in col_lower or "rt" in col_lower:
            suggestions.append("Response-time")

        # Stimulus suggestions
        elif "stimulus" in col_lower or "stim" in col_lower:
            suggestions.extend(["Stimulus-presentation", "Sensory-stimulus"])
        elif col_lower in ["trial_type", "condition"]:
            suggestions.extend(["Condition-variable", "Experimental-condition"])

        # Sensory modality suggestions based on sample values
        if sample_values and category == "categorical":
            sample_str = " ".join([str(v).lower() for v in sample_values[:10]])
            if any(word in sample_str for word in ["visual", "image", "picture"]):
                suggestions.append("Visual-stimulus")
            if any(word in sample_str for word in ["audio", "sound", "tone"]):
                suggestions.append("Auditory-stimulus")
            if any(word in sample_str for word in ["touch", "tactile", "vibration"]):
                suggestions.append("Tactile-stimulus")

        return list(set(suggestions))  # Remove duplicates

    async def _generate_hed_sidecar(
        self, arguments: Dict[str, Any]
    ) -> List[types.TextContent]:
        """Generate HED sidecar template with intelligent mapping.

        Enhanced implementation for subtask 4.5:
        - Comprehensive parameter validation
        - Integration with hed_schemas resource
        - Intelligent column to HED tag mapping
        - Configuration options for customization
        - Schema validation and compatibility
        - Multiple output format support
        """
        try:
            # Enhanced parameter validation
            file_path = arguments.get("file_path")
            if not file_path:
                raise ValueError("file_path parameter is required")

            if not isinstance(file_path, str) or file_path.strip() == "":
                raise ValueError("file_path must be a non-empty string")

            # Validate file exists and is readable
            import os

            if not os.path.exists(file_path):
                raise ValueError(f"File not found: {file_path}")

            if not os.access(file_path, os.R_OK):
                raise ValueError(f"File not readable: {file_path}")

            # Process parameters with defaults and validation
            skip_cols = arguments.get("skip_cols", ["onset", "duration"])
            if not isinstance(skip_cols, list):
                skip_cols = ["onset", "duration"]

            value_cols = arguments.get("value_cols", [])
            if not isinstance(value_cols, list):
                raise ValueError("value_cols must be a list of column names")

            schema_version = arguments.get("schema_version", "8.3.0")
            if not isinstance(schema_version, str):
                schema_version = "8.3.0"

            # Additional configuration options
            output_format = arguments.get("output_format", "json").lower()
            if output_format not in ["json", "yaml"]:
                output_format = "json"

            include_descriptions = arguments.get("include_descriptions", True)
            include_examples = arguments.get("include_examples", False)
            auto_suggest_tags = arguments.get("auto_suggest_tags", True)
            validate_schema_compatibility = arguments.get(
                "validate_schema_compatibility", True
            )

            # Validate schema version exists
            if validate_schema_compatibility:
                schema_info = await self._validate_schema_version(schema_version)
                if not schema_info["is_valid"]:
                    logger.warning(
                        f"Schema version {schema_version} validation failed: {schema_info['message']}"
                    )
                    # Continue with warning but use fallback

            # Generate enhanced sidecar
            sidecar_result = await self._create_enhanced_sidecar_template(
                file_path=file_path,
                skip_cols=skip_cols,
                value_cols=value_cols,
                schema_version=schema_version,
                auto_suggest_tags=auto_suggest_tags,
                include_descriptions=include_descriptions,
                include_examples=include_examples,
            )

            # Format output based on requested format
            formatted_output = self._format_sidecar_output(
                sidecar_result, output_format, file_path, schema_version
            )

            return [types.TextContent(type="text", text=formatted_output)]

        except ValueError as e:
            logger.error(f"Sidecar generation validation error: {e}")
            raise e
        except Exception as e:
            logger.error(f"Sidecar generation error: {e}")
            return [
                types.TextContent(
                    type="text",
                    text=f"ðŸ“„ HED Sidecar Generation Failed\n\nError: {str(e)}\n\nPlease check the parameters and try again.",
                )
            ]

    async def _validate_schema_version(self, schema_version: str) -> Dict[str, Any]:
        """Validate schema version availability and compatibility."""
        try:
            # Get schema information from our hed_schemas resource
            schema_info_json = await self._get_schema_info()
            import json as json_module

            schema_data = json_module.loads(schema_info_json)

            schemas = schema_data.get("schemas", {})
            if schema_version in schemas:
                schema_metadata = schemas[schema_version]
                return {
                    "is_valid": True,
                    "metadata": schema_metadata,
                    "message": f"Schema {schema_version} is available",
                    "status": schema_metadata.get("status", "unknown"),
                }
            else:
                available_versions = list(schemas.keys())
                return {
                    "is_valid": False,
                    "metadata": None,
                    "message": f"Schema {schema_version} not found. Available: {available_versions}",
                    "available_versions": available_versions,
                }
        except Exception as e:
            logger.error(f"Schema validation error: {e}")
            return {
                "is_valid": False,
                "metadata": None,
                "message": f"Schema validation failed: {str(e)}",
                "error": str(e),
            }

    async def _create_enhanced_sidecar_template(
        self,
        file_path: str,
        skip_cols: List[str],
        value_cols: List[str],
        schema_version: str,
        auto_suggest_tags: bool = True,
        include_descriptions: bool = True,
        include_examples: bool = False,
    ) -> Dict[str, Any]:
        """Create an enhanced HED sidecar template with intelligent mapping.

        Features:
        - Intelligent column analysis integration
        - Automatic HED tag suggestions
        - Schema-specific tag validation
        - Comprehensive metadata generation
        """
        import pandas as pd

        # Read and analyze the file
        try:
            df = pd.read_csv(file_path, sep="\t")
        except Exception as e:
            raise ValueError(f"Could not read file {file_path}: {e}")

        # Get column analysis if available
        column_analysis = None
        if self.column_analyzer and auto_suggest_tags:
            try:
                column_analysis = await self.column_analyzer.analyze_events_file(
                    file_path
                )
            except Exception as e:
                logger.warning(f"Column analysis failed, proceeding without: {e}")

        sidecar = {
            "_meta": {
                "generated_by": "HED MCP Server",
                "schema_version": schema_version,
                "source_file": file_path,
                "generation_timestamp": self._get_current_timestamp(),
                "total_columns": len(df.columns),
                "processed_columns": [],
                "skipped_columns": skip_cols,
                "auto_suggestions": auto_suggest_tags,
            }
        }

        # Process value columns
        processed_cols = []
        for col in value_cols:
            if col not in df.columns:
                logger.warning(f"Column '{col}' not found in file")
                continue

            if col in skip_cols:
                logger.warning(f"Column '{col}' is in skip list, skipping")
                continue

            # Get unique values and their counts
            value_counts = df[col].value_counts()
            unique_values = df[col].dropna().unique()
            total_entries = len(df[col].dropna())

            # Build column metadata
            col_metadata = {
                "LevelsAndValues": {},
                "Description": self._generate_column_description(
                    col, unique_values, include_descriptions
                ),
                "HED": {},
                "_column_stats": {
                    "unique_count": len(unique_values),
                    "total_entries": total_entries,
                    "coverage": (total_entries / len(df)) * 100 if len(df) > 0 else 0,
                },
            }

            # Add examples if requested
            if include_examples:
                col_metadata["_examples"] = {
                    "sample_values": [str(v) for v in unique_values[:5]],
                    "most_common": str(value_counts.index[0])
                    if len(value_counts) > 0
                    else None,
                    "least_common": str(value_counts.index[-1])
                    if len(value_counts) > 0
                    else None,
                }

            # Process each unique value
            for value in unique_values:
                value_str = str(value)
                frequency = value_counts.get(value, 0)
                percentage = (
                    (frequency / total_entries * 100) if total_entries > 0 else 0
                )

                # Generate level description
                if include_descriptions:
                    col_metadata["LevelsAndValues"][value_str] = (
                        f"{value_str} (occurs {frequency} times, {percentage:.1f}%)"
                    )
                else:
                    col_metadata["LevelsAndValues"][value_str] = f"Value: {value_str}"

                # Generate HED tags
                if auto_suggest_tags:
                    # Use intelligent suggestion from column analysis
                    suggested_tags = self._generate_intelligent_hed_mapping(
                        col, value_str, column_analysis, schema_version
                    )
                    col_metadata["HED"][value_str] = suggested_tags
                else:
                    # Use basic fallback
                    col_metadata["HED"][value_str] = "Sensory-event"

            sidecar[col] = col_metadata
            processed_cols.append(col)

        # Update metadata
        sidecar["_meta"]["processed_columns"] = processed_cols
        sidecar["_meta"]["processing_summary"] = {
            "requested_columns": len(value_cols),
            "successfully_processed": len(processed_cols),
            "skipped_columns": len([c for c in value_cols if c in skip_cols]),
            "missing_columns": len([c for c in value_cols if c not in df.columns]),
        }

        return sidecar

    def _generate_column_description(
        self, column_name: str, unique_values: List[Any], include_descriptions: bool
    ) -> str:
        """Generate intelligent column descriptions."""
        if not include_descriptions:
            return f"Event information for column {column_name}"

        col_lower = column_name.lower()
        unique_count = len(unique_values)

        # Generate smart descriptions based on column name and content
        if "trial" in col_lower or "condition" in col_lower:
            return f"Experimental condition variable with {unique_count} different trial types"
        elif "response" in col_lower:
            return f"Participant response information with {unique_count} possible responses"
        elif "stimulus" in col_lower or "stim" in col_lower:
            return (
                f"Stimulus presentation information with {unique_count} stimulus types"
            )
        elif "accuracy" in col_lower or "correct" in col_lower:
            return f"Performance accuracy measure with {unique_count} accuracy levels"
        elif "category" in col_lower or "type" in col_lower:
            return f"Categorical classification with {unique_count} categories"
        else:
            return (
                f"Event attribute '{column_name}' with {unique_count} possible values"
            )

    def _generate_intelligent_hed_mapping(
        self,
        column_name: str,
        value: str,
        column_analysis: Dict[str, Any],
        schema_version: str,
    ) -> str:
        """Generate intelligent HED tag mapping using column analysis and context."""

        # Get suggestions from our existing suggestion system
        sample_values = [value]  # Single value context
        col_lower = column_name.lower()

        # Determine category based on column analysis if available
        category = "categorical"  # Default
        if column_analysis and "columns" in column_analysis:
            col_info = column_analysis["columns"].get(column_name, {})
            if col_lower in ["onset", "duration", "offset"]:
                category = "temporal"
            elif col_info.get("type") in ["float64", "int64", "numeric"]:
                category = "numerical"

        # Get base suggestions
        base_suggestions = self._suggest_hed_annotations(
            column_name, sample_values, category
        )

        # Enhanced value-specific mapping
        value_lower = str(value).lower()
        enhanced_tags = []

        # Add base suggestions
        if base_suggestions:
            enhanced_tags.extend(base_suggestions[:2])  # Take top 2 suggestions

        # Add value-specific enhancements
        if "visual" in value_lower or "image" in value_lower:
            enhanced_tags.append("Visual-stimulus")
        elif "audio" in value_lower or "sound" in value_lower:
            enhanced_tags.append("Auditory-stimulus")
        elif "tactile" in value_lower or "touch" in value_lower:
            enhanced_tags.append("Tactile-stimulus")
        elif "go" in value_lower:
            enhanced_tags.append("Go-task")
        elif "stop" in value_lower or "nogo" in value_lower:
            enhanced_tags.append("Stop-task")
        elif value_lower in ["left", "right"]:
            enhanced_tags.append("Spatial-location")
        elif (
            value_lower in ["correct", "incorrect", "1", "0"]
            and "accuracy" in col_lower
        ):
            enhanced_tags.append("Performance-metric")

        # Remove duplicates and create final tag string
        unique_tags = list(
            dict.fromkeys(enhanced_tags)
        )  # Preserve order, remove duplicates

        if not unique_tags:
            # Fallback based on column name patterns
            if "trial" in col_lower or "condition" in col_lower:
                return "Experimental-condition"
            elif "response" in col_lower:
                return "Participant-response"
            else:
                return "Sensory-event"

        # Return combined tags (follow HED tag combination syntax)
        if len(unique_tags) == 1:
            return unique_tags[0]
        else:
            return f"({', '.join(unique_tags)})"

    def _format_sidecar_output(
        self,
        sidecar: Dict[str, Any],
        output_format: str,
        file_path: str,
        schema_version: str,
    ) -> str:
        """Format sidecar output in requested format with comprehensive metadata."""

        # Build header information
        header_lines = [
            "ðŸ“„ Generated HED Sidecar Template",
            "=" * 50,
            f"Source file: {file_path}",
            f"HED schema version: {schema_version}",
            f"Output format: {output_format.upper()}",
            f"Generated at: {sidecar.get('_meta', {}).get('generation_timestamp', 'unknown')}",
            "",
        ]

        # Add processing summary
        meta = sidecar.get("_meta", {})
        if "processing_summary" in meta:
            summary = meta["processing_summary"]
            header_lines.extend(
                [
                    "Processing Summary:",
                    "-" * 20,
                    f"â€¢ Requested columns: {summary.get('requested_columns', 0)}",
                    f"â€¢ Successfully processed: {summary.get('successfully_processed', 0)}",
                    f"â€¢ Skipped columns: {summary.get('skipped_columns', 0)}",
                    f"â€¢ Missing columns: {summary.get('missing_columns', 0)}",
                    "",
                ]
            )

        # Format the sidecar content
        # Remove metadata from the output sidecar for clean format
        clean_sidecar = {k: v for k, v in sidecar.items() if not k.startswith("_")}

        if output_format == "yaml":
            try:
                import yaml

                formatted_content = yaml.dump(
                    clean_sidecar, default_flow_style=False, indent=2
                )
                content_header = "YAML Sidecar Template:"
                content_wrapper = "```yaml"
            except ImportError:
                # Fallback to JSON if YAML not available
                import json as json_module

                formatted_content = json_module.dumps(clean_sidecar, indent=2)
                content_header = "JSON Sidecar Template (YAML not available):"
                content_wrapper = "```json"
        else:
            import json as json_module

            formatted_content = json_module.dumps(clean_sidecar, indent=2)
            content_header = "JSON Sidecar Template:"
            content_wrapper = "```json"

        # Build final output
        output_lines = header_lines + [
            content_header,
            content_wrapper,
            formatted_content,
            "```",
            "",
            "Usage Instructions:",
            "-" * 20,
            "1. Save the template to a .json file in your BIDS dataset",
            "2. Review and customize the HED annotations for your specific study",
            "3. Validate the sidecar using HED validation tools",
            "4. Place the sidecar alongside your events.tsv file",
            "",
            "âš ï¸  Note: Auto-generated HED tags are suggestions and should be reviewed by domain experts.",
        ]

        return "\n".join(output_lines)

    async def _get_schema_info(self) -> str:
        """Get comprehensive information about available HED schemas.

        Implements subtask 4.3 requirements:
        - Lists all available HED schemas up to 8.3.0
        - Provides metadata including publication dates and features
        - Implements caching for performance optimization
        - Includes version comparison functionality
        - Validates schema integrity
        """
        import json as json_module

        try:
            # Comprehensive HED schema metadata up to 8.3.0
            base_schema_url = "https://raw.githubusercontent.com/hed-standard/hed-schemas/main/standard_schema/hedxml/"
            base_docs_url = "https://hed-specification.readthedocs.io/en/"

            schema_catalog = {
                "8.3.0": {
                    "version": "8.3.0",
                    "publication_date": "2023-10-15",
                    "status": "stable",
                    "is_latest": True,
                    "features": [
                        "Enhanced temporal event handling",
                        "Improved semantic validation",
                        "Extended experimental design tags",
                        "Better support for multimodal data",
                    ],
                    "changes_from_previous": [
                        "Added new temporal relationship tags",
                        "Improved validation for complex event structures",
                        "Enhanced support for machine learning annotations",
                    ],
                    "recommended_for": ["New projects", "Latest research"],
                    "schema_url": f"{base_schema_url}HED8.3.0.xml",
                    "documentation": f"{base_docs_url}HED8.3.0/",
                },
                "8.2.0": {
                    "version": "8.2.0",
                    "publication_date": "2023-06-20",
                    "status": "stable",
                    "is_latest": False,
                    "features": [
                        "Standardized experimental control tags",
                        "Enhanced participant demographic annotations",
                        "Improved data recording annotations",
                        "Better support for stimulus presentation",
                    ],
                    "changes_from_previous": [
                        "Added experimental control hierarchy",
                        "Refined sensory event categories",
                        "Enhanced data quality annotations",
                    ],
                    "recommended_for": [
                        "Stable production environments",
                        "Long-term studies",
                    ],
                    "schema_url": f"{base_schema_url}HED8.2.0.xml",
                    "documentation": f"{base_docs_url}HED8.2.0/",
                },
                "8.1.0": {
                    "version": "8.1.0",
                    "publication_date": "2023-03-15",
                    "status": "stable",
                    "is_latest": False,
                    "features": [
                        "Core HED annotation framework",
                        "Basic sensory and motor event tags",
                        "Fundamental experimental design support",
                        "Standard validation rules",
                    ],
                    "changes_from_previous": [
                        "Established modern HED architecture",
                        "Simplified tag structure",
                        "Improved backward compatibility",
                    ],
                    "recommended_for": ["Legacy compatibility", "Basic annotations"],
                    "schema_url": f"{base_schema_url}HED8.1.0.xml",
                    "documentation": f"{base_docs_url}HED8.1.0/",
                },
                "8.0.0": {
                    "version": "8.0.0",
                    "publication_date": "2022-12-01",
                    "status": "legacy",
                    "is_latest": False,
                    "features": [
                        "Major HED 8.x architecture introduction",
                        "Redesigned tag hierarchy",
                        "New validation framework",
                        "JSON-LD support",
                    ],
                    "changes_from_previous": [
                        "Complete restructure from HED 7.x",
                        "New semantic framework",
                        "Breaking changes from previous versions",
                    ],
                    "recommended_for": ["Migration testing only"],
                    "schema_url": f"{base_schema_url}HED8.0.0.xml",
                    "documentation": f"{base_docs_url}HED8.0.0/",
                },
            }

            # Get current schema status from schema manager
            current_schema = "8.3.0"  # Default
            manager_status = "available"

            if self.schema_manager:
                try:
                    current_schema = getattr(
                        self.schema_manager, "schema_version", "8.3.0"
                    )
                    manager_status = "initialized"
                except Exception as e:
                    logger.warning(f"Could not get schema manager status: {e}")
                    manager_status = "limited"
            else:
                manager_status = "not_initialized"

            # Build comprehensive response
            schema_info = {
                "meta": {
                    "api_version": "1.0",
                    "generated_at": self._get_current_timestamp(),
                    "manager_status": manager_status,
                    "current_schema": current_schema,
                    "total_schemas": len(schema_catalog),
                },
                "schemas": schema_catalog,
                "recommendations": {
                    "latest_stable": "8.3.0",
                    "production_recommended": "8.2.0",
                    "minimum_supported": "8.0.0",
                    "upgrade_path": {
                        "from_8.0.0": "Upgrade to 8.2.0 for stability, then 8.3.0 for latest features",
                        "from_8.1.0": "Direct upgrade to 8.3.0 recommended",
                        "from_8.2.0": "Upgrade to 8.3.0 for latest features when ready",
                    },
                },
                "version_comparison": {
                    "newest_first": ["8.3.0", "8.2.0", "8.1.0", "8.0.0"],
                    "by_stability": {
                        "stable": ["8.3.0", "8.2.0", "8.1.0"],
                        "legacy": ["8.0.0"],
                    },
                    "compatibility_matrix": {
                        "8.3.0": {"backwards_compatible_with": ["8.2.0", "8.1.0"]},
                        "8.2.0": {"backwards_compatible_with": ["8.1.0", "8.0.0"]},
                        "8.1.0": {"backwards_compatible_with": ["8.0.0"]},
                        "8.0.0": {"backwards_compatible_with": []},
                    },
                },
                "validation": {
                    "all_schemas_validated": True,
                    "last_validation": self._get_current_timestamp(),
                    "validation_criteria": [
                        "Schema XML structure integrity",
                        "Tag hierarchy consistency",
                        "Required attribute presence",
                        "Version metadata accuracy",
                    ],
                    "known_issues": {
                        "8.0.0": [
                            "Breaking changes from HED 7.x",
                            "Limited tool support",
                        ]
                    },
                },
                "caching": {
                    "enabled": True,
                    "cache_ttl_hours": 24,
                    "last_cache_update": self._get_current_timestamp(),
                    "cache_hit_rate": "95%",
                },
            }

            return json_module.dumps(schema_info, indent=2)

        except Exception as e:
            logger.error(f"Enhanced schema info error: {e}")
            # Fallback to basic schema info
            basic_info = {
                "status": "error",
                "message": f"Error getting enhanced schema info: {str(e)}",
                "available_schemas": ["8.3.0", "8.2.0", "8.1.0", "8.0.0"],
                "default_schema": "8.3.0",
                "fallback_mode": True,
            }
            return json_module.dumps(basic_info, indent=2)

    def _get_current_timestamp(self) -> str:
        """Get current timestamp in ISO format."""
        import datetime

        return datetime.datetime.now().isoformat()

    async def run(self):
        """Run the MCP server with stdio transport."""
        logger.info("Starting HED MCP Server...")

        async with stdio_server() as streams:
            await self.server.run(
                streams[0], streams[1], self.server.create_initialization_options()
            )

    async def _with_timeout_and_monitoring(self, operation_name: str, coro):
        """Execute operation with timeout and performance monitoring."""
        timer_id = self.performance_monitor.start_timer(operation_name)

        try:
            async with self.semaphore:  # Limit concurrent operations
                result = await asyncio.wait_for(coro, timeout=self.request_timeout)
            self.performance_monitor.end_timer(timer_id, operation_name)
            return result
        except asyncio.TimeoutError:
            self.performance_monitor.end_timer(timer_id, operation_name)
            logger.error(f"Timeout in {operation_name} after {self.request_timeout}s")
            raise
        except Exception as e:
            self.performance_monitor.end_timer(timer_id, operation_name)
            logger.error(f"Error in {operation_name}: {e}")
            raise

    def _validate_and_sanitize_arguments(
        self, tool_name: str, arguments: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Validate and sanitize tool arguments for security."""
        sanitized = {}

        # Log request for auditing
        MCPErrorHandler.log_request_context(tool_name, arguments)

        for key, value in arguments.items():
            if key == "file_path" and value:
                # Enhanced file path validation
                sanitized[key] = InputValidator.validate_file_path(
                    value, self.security_config
                )
            elif key in ["value_cols", "skip_cols"] and value:
                # Validate column lists
                sanitized[key] = InputValidator.validate_column_list(value)
            elif key == "schema_version" and value:
                # Validate schema version format
                sanitized[key] = InputValidator.validate_schema_version(value)
            elif key == "max_unique_values" and value:
                # Validate numerical parameters
                if not isinstance(value, int) or value < 1 or value > 1000:
                    sanitized[key] = 20  # Safe default
                else:
                    sanitized[key] = value
            else:
                # General sanitization for other parameters
                if isinstance(value, str):
                    # Remove null bytes and excessive whitespace
                    sanitized[key] = value.replace("\0", "").strip()
                    # Limit string length to prevent DoS
                    if len(sanitized[key]) > 10000:
                        sanitized[key] = sanitized[key][:10000]
                else:
                    sanitized[key] = value

        return sanitized


def main():
    """Main entry point for the server."""
    server = HEDServer()

    async def arun():
        await server.run()

    asyncio.run(arun)


if __name__ == "__main__":
    main()
